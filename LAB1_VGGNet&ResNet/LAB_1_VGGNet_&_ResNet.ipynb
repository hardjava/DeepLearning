{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3QJpzZKVAn6r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHWqOeX0DtOf"
      },
      "source": [
        "### 1. VGGNet with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWeEYLiSj9Zx"
      },
      "source": [
        "### Implementing VGGNet\n",
        "\n",
        "> 1. **Dataset**\n",
        ">> - Images from the first three categories in CIFAR-10. (Due to the computational constraints.)  <br>\n",
        "     Three categories : plane, car, bird  /  The number of training images : 15,000   /  The number of test images : 3,000\n",
        ">> - Augmented with flipping and random cropping.\n",
        ">\n",
        "> 2. **Network architecture**\n",
        ">> - Type-D configuration in the paper (+ 3-way classifier after convolutional layers).\n",
        ">> - ReLU activation.\n",
        ">> - No dropout for simplicity.\n",
        ">> - We will apply **batch-normalization** after every convolution which is not used in the paper (otherwise, hard to optimize).\n",
        ">> - **Conv2d -> BatchNorm2d -> ReLU**\n",
        ">>\n",
        ">> <table><tr>\n",
        ">> <td> <img src=\"https://docs.google.com/uc?export=download&id=1OiTmrplD9gOrEJizLChyLp31R0QtoeHv\" alt=\"no_image\" style=\"width: 550px;\"/> </td>\n",
        ">> <td> <img src=\"https://docs.google.com/uc?export=download&id=1bBvAOdJeskMMyOrZtBCCnkEEgq9PgjX9\" alt=\"no_image\" style=\"width: 250px;\"/> </td>\n",
        ">> </tr></table>\n",
        ">>\n",
        ">> <font size=\"0.5\"> Figure from <br>\n",
        ">> [1] https://www.quora.com/What-is-the-VGG-neural-network </font>\n",
        ">\n",
        "> 3. **Loss function**\n",
        ">> - Cross-entropy loss between outputs & ground-truths. <br>\n",
        "     Note that `nn.CrossEntroyLoss` takes logits before softmax as network outputs and scalar index (not one-hot vector) as ground-truths.<br>\n",
        "     See https://pytorch.org/docs/stable/nn.html#crossentropyloss for details.\n",
        ">\n",
        "> 4. **Training**\n",
        ">> - Default weight initialization for simplicity.\n",
        ">> - SGD optimizer with `learning rate = 1e-2`, `momentum = 0.9`, and `weight_decay = 5e-4`.\n",
        ">> - 20 epochs without learning rate scheduling.\n",
        ">\n",
        "> 5. **Evaluation metric**\n",
        ">> - Classification accuracy (i.e., the percentage of correct predictions).\n",
        ">\n",
        ">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9jfQg2frQ7w",
        "outputId": "1657d2a3-73e2-4bad-a5d5-4d416f2c016b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 1: LOADING DATASET\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "print('STEP 1: LOADING DATASET')\n",
        "# CIFAR-10 dataset을 Load & Transform\n",
        "# torchvision.transforms 를 이용하여 전처리\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4), # 32 * 32 크기로 무작위로 자름 (주변에 padding 4 추가)\n",
        "    transforms.RandomHorizontalFlip(), # 무작위로 좌우 반전\n",
        "    transforms.ToTensor(), # Tensor로 변환 (0 ~ 1 범위로 정규화 됨)\n",
        "    transforms.Normalize((0.4194, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # 정규화 (평균 및 표준편차를 기준으로 정규화)\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(), # Test data는 변형 없이 원본 이미지 그대로 사용해야 일관된 평가 가능\n",
        "    transforms.Normalize((0.4194, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # 정규화만 적용 (데이터 증강 x)\n",
        "])\n",
        "\n",
        "train_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                              train=True,\n",
        "                              transform=transform_train,\n",
        "                              download=True)\n",
        "\n",
        "test_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                             train=False,\n",
        "                             transform=transform_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8YTOGnQwssaw"
      },
      "outputs": [],
      "source": [
        "# CIFAR-10 dataset에서 레이블이 0, 1, 2 인 데이터만 선택하여 축소된 dataset을 생성\n",
        "reduced_train_dataset = []\n",
        "for images, labels in train_dataset:\n",
        "  if labels < 3:\n",
        "    reduced_train_dataset.append((images, labels))\n",
        "\n",
        "reduced_test_dataset = []\n",
        "for images, labels in test_dataset:\n",
        "  if labels < 3:\n",
        "    reduced_test_dataset.append((images, labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNkO5PryuLP0",
        "outputId": "b8969cbf-d81e-4fe6-e204-17bea1f44b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of training images:  15000\n",
            "The number of test images:  3000\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of training images: \", len(reduced_train_dataset))\n",
        "print(\"The number of test images: \", len(reduced_test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGkpzkquujGC",
        "outputId": "95b8b7ec-2636-4bfd-ed89-84aeedac6ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 2: MAKING DATASET ITERABLE\n"
          ]
        }
      ],
      "source": [
        "print(\"STEP 2: MAKING DATASET ITERABLE\")\n",
        "# CIFAR-10 dataset을 batch 단위로 load 할 수 있도록 DataLoader를 생성\n",
        "# train_loader: train data를 128개씩 랜덤 배치로 로드\n",
        "train_loader = torch.utils.data.DataLoader(dataset=reduced_train_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True) # 모델이 특정 순서에 과적합되지 않도록 데이터 순서를 무작위로 만듦\n",
        "# test_loader = test data를 100개씩 순서를 유지하며 로드\n",
        "test_loader = torch.utils.data.DataLoader(dataset=reduced_test_dataset,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=False) # 테스트 데이터는 항상 같은 순서로 평가해야 하므로 섞지 않음\n",
        "# CIFAR-10 은 10개의 클래스로 구성된 데이터 셋\n",
        "# 각 인덱스에 해당하는 클래스 이름을 튜플로 저장\n",
        "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G23xdnTYwwzh"
      },
      "source": [
        "### Visualize a few images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dqAMP24Xwwik"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bTcl01IywrzD"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "  inp = inp.numpy().transpose((1, 2, 0)) # PyTorch Tensor -> Numpy 배열로 변환\n",
        "  # PyTorch 이미지 Tensor는 (채널, 높이, 너비) 순서이므로 Matplotlib에서 올바르게 표시되도록 (높이, 너비, 채널) 로 변환\n",
        "  mean = np.array([0.4194, 0.4822, 0.4465]) # 이미지 정규화를 적용했으므로 이를 다시 원래 값으로 복원\n",
        "  std = np.array([0.2023, 0.1994, 0.2010])\n",
        "  inp = std * inp + mean\n",
        "  inp = np.clip(inp, 0, 1) # 이미지 픽셀 값이 0 ~ 1 범위를 벗어나지 않도록 조정\n",
        "  plt.imshow(inp)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.pause(0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "tcXPBdt2xX1H",
        "outputId": "9a8dff59-62de-40bc-d338-afdf2d6b226f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_loader_sample = torch.utils.data.DataLoader(dataset=reduced_train_dataset,\n",
        "                                                  batch_size=4,\n",
        "                                                  shuffle=True)\n",
        "\n",
        "inputs, classes = next(iter(train_loader_sample))\n",
        "# inputs: 배치 내 4개의 이미지 Tensor\n",
        "# classes: 각 이미지에 대한 클래스 라벨(숫자)\n",
        "out = torchvision.utils.make_grid(inputs) # 4개의 이미지를 한 장의 이미지로 합쳐서 그리드 형태로 표시, 이미지 간 패딩을 추가하여 하나의 큰 이미지로 정렬\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PPAh_2HzoI7"
      },
      "source": [
        "### VGG 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UidGw51Zxxw8",
        "outputId": "5ef365e9-eb57-4b56-b174-bd33505ebfd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 3: CREATE MODEL CLASS (VGG16)\n"
          ]
        }
      ],
      "source": [
        "print(\"STEP 3: CREATE MODEL CLASS (VGG16)\")\n",
        "\n",
        "cfg = [64, 64, 'MP', 128, 128, 'MP', 256, 256, 256, 'MP', 512, 512, 512, 'MP', 512, 512, 512, 'MP'] # VGG16의 계층 구조 정의\n",
        "\n",
        "class VGG(nn.Module):\n",
        "  def __init__(self, in_channels=3):\n",
        "    super(VGG, self).__init__()\n",
        "    self.VGG16 = self._make_layers(cfg, in_channels) # VGG16 모델의 CNN 부분을 구성\n",
        "    self.classifier = nn.Linear(512, 3) # Fully Connected Layer (출력 크기: num_classes=3)\n",
        "\n",
        "  def forward(self, x): # Forward Propagation\n",
        "    out = self.VGG16(x) # CNN 계층을 통과\n",
        "    out = out.view(out.size(0), -1) # Feature Map을 1D 벡터로 펼침 (Flatten)\n",
        "    out = self.classifier(out) # Fully Connected Layer 통과 후 최종 예측값 반환\n",
        "    # FC Layer를 거쳐 3개의 클래스에 대한 예측값(logit)을 출력\n",
        "    return out\n",
        "\n",
        "  def _make_layers(self, cfg, in_channels):\n",
        "    layers = []\n",
        "\n",
        "    for x in cfg:\n",
        "      if x == 'MP':\n",
        "        layers.append(nn.MaxPool2d(kernel_size=2))\n",
        "      else:\n",
        "        layers.append(nn.Conv2d(in_channels=in_channels, out_channels=x, kernel_size=3, padding=1))\n",
        "        layers.append(nn.BatchNorm2d(x))\n",
        "        layers.append(nn.ReLU())\n",
        "        in_channels=x\n",
        "\n",
        "    return nn.Sequential(*layers) # 모든 layer 를 Sequential 로 묶어서 하나의 모듈로 반환 (CNN 모델의 여러 계층을 하나의 연속된 블록으로 정의하기 위함)\n",
        "    # 각 계층이 자동으로 순서대로 실행됨\n",
        "\n",
        "# Feature map 의 개수는 channel 수와 같다\n",
        "# Feature map = CNN이 kernel을 사용하여 이미지의 특징을 추출한 결과 (각 필터는 서로 다른 특징)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Tp7ARhzvVo",
        "outputId": "a6bcd4cb-644f-4aa9-d4ef-7791a218e5ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 4: INSTANTIATE MODEL CLASS\n",
            "The number of parameters :  14724675\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (VGG16): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU()\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU()\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU()\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU()\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU()\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU()\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU()\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU()\n",
              "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU()\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU()\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU()\n",
              "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('STEP 4: INSTANTIATE MODEL CLASS')\n",
        "# 모델 인스턴스화 및 파라미터 개수 계산\n",
        "# VGG 모델을 생성하고, GPU 또는 CPU에 로드하는 과정\n",
        "model = VGG()\n",
        "num_total_params = sum(p.numel() for p in model.parameters()) # 모델 내부의 모든 가중치 및 편향 (weight & bias) 텐서를 가져옴\n",
        "# p.numel(): 해당 가중치 tensor의 총 파라미터 개수 반환\n",
        "print(\"The number of parameters : \", num_total_params)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTseZhsN8D51",
        "outputId": "4c2fe8ee-3341-4d46-d754-a6ad8db4e780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 5: INSTANTIATE LOSS CLASS\n",
            "STEP 6: INSTANTIATE OPTIMIZER CLASS\n"
          ]
        }
      ],
      "source": [
        "print(\"STEP 5: INSTANTIATE LOSS CLASS\")\n",
        "criterion = nn.CrossEntropyLoss() # 분류 문제에서 사용되는 손실 함수, 다중 클래스 분류에서 자주 사용됨\n",
        "# 내부적으로 Softmax + Negative Log Likelihood Loss 를 포함\n",
        "# 모델이 예측값 (logits)와 실제 정답 (class index)를 비교하여 오차 계산\n",
        "print(\"STEP 6: INSTANTIATE OPTIMIZER CLASS\")\n",
        "\n",
        "learing_rate = 1e-2\n",
        "momentum = 0.9\n",
        "weight_decay = 5e-4\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learing_rate, momentum = momentum, weight_decay = weight_decay)\n",
        "# 확률적 경사 하강법 (Stochastic Gradient Descent), 모델의 모든 파라미터 업데이트, weight_decay -> L2 정규화\n",
        "# SGD -> Loss Function 을 줄이기 위해 가중치를 업데이트하는 알고리즘. 기울기를 계산하여 반대 방향으로 이동"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57CVfJ8y_wMD"
      },
      "source": [
        "### Train the VGG 16 model and print test accuracy for every epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiIlDr3f-Ac9",
        "outputId": "657d7b52-6482-4a6a-80c7-76fb55a62b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 7: TRAIN THE MODEL\n",
            "Epochs: 0. Loss: 0.6413388848304749. Accuracy: 82.5, Elapsed time: 7.634923219680786 sec\n",
            "Epochs: 1. Loss: 0.30767199397087097. Accuracy: 86.36666666666666, Elapsed time: 6.62676215171814 sec\n",
            "Epochs: 2. Loss: 0.7385739684104919. Accuracy: 87.56666666666666, Elapsed time: 6.6397929191589355 sec\n",
            "Epochs: 3. Loss: 0.20916219055652618. Accuracy: 90.1, Elapsed time: 6.6617913246154785 sec\n",
            "Epochs: 4. Loss: 0.2061227411031723. Accuracy: 89.56666666666666, Elapsed time: 6.666800022125244 sec\n",
            "Epochs: 5. Loss: 0.1492268145084381. Accuracy: 90.26666666666667, Elapsed time: 6.707655906677246 sec\n",
            "Epochs: 6. Loss: 0.07712143659591675. Accuracy: 91.76666666666667, Elapsed time: 6.74907922744751 sec\n",
            "Epochs: 7. Loss: 0.14920081198215485. Accuracy: 91.46666666666667, Elapsed time: 6.797206163406372 sec\n",
            "Epochs: 8. Loss: 0.04695770516991615. Accuracy: 89.33333333333333, Elapsed time: 6.841727018356323 sec\n",
            "Epochs: 9. Loss: 0.1836860030889511. Accuracy: 91.46666666666667, Elapsed time: 6.889595031738281 sec\n",
            "Epochs: 10. Loss: 0.10429233312606812. Accuracy: 92.13333333333334, Elapsed time: 6.96177339553833 sec\n",
            "Epochs: 11. Loss: 0.06132904067635536. Accuracy: 92.26666666666667, Elapsed time: 7.042141675949097 sec\n",
            "Epochs: 12. Loss: 0.0028629377484321594. Accuracy: 90.9, Elapsed time: 7.088004112243652 sec\n",
            "Epochs: 13. Loss: 0.029846666380763054. Accuracy: 91.56666666666666, Elapsed time: 7.159311056137085 sec\n",
            "Epochs: 14. Loss: 0.00648249639198184. Accuracy: 92.03333333333333, Elapsed time: 7.226328134536743 sec\n",
            "Epochs: 15. Loss: 0.051910046488046646. Accuracy: 91.76666666666667, Elapsed time: 7.286125421524048 sec\n",
            "Epochs: 16. Loss: 0.06726940721273422. Accuracy: 91.86666666666666, Elapsed time: 7.328394174575806 sec\n",
            "Epochs: 17. Loss: 0.003402576083317399. Accuracy: 92.4, Elapsed time: 7.341660737991333 sec\n",
            "Epochs: 18. Loss: 0.0008688797242939472. Accuracy: 91.46666666666667, Elapsed time: 7.32280421257019 sec\n",
            "Epochs: 19. Loss: 0.02199510484933853. Accuracy: 92.3, Elapsed time: 7.286590814590454 sec\n"
          ]
        }
      ],
      "source": [
        "# 모델 학습 및\n",
        "# 훈련 데이터: 전체 데이터를 batch_size=128로 쪼갬, 한 번의 배치에서 128개씩 모델이 학습. 총 391 번의 배치가 실행되면 1 에포크 종료\n",
        "# 테스트 데이터: 전체 데이터를 batch_size=100으로 쪼갬, 한 번의 배치에서 100개씩 모델이 예측 총 100 번의 배치가 실행되면 테스트 완료\n",
        "import time\n",
        "print('STEP 7: TRAIN THE MODEL')\n",
        "num_epochs = 20\n",
        "# 1 Epoch = 전체 데이터 한 바퀴\n",
        "for epoch in range(num_epochs): # 전체 데이터세을 num_epochs 만큼 반복 학습\n",
        "  start_time = time.time()\n",
        "  for i, (images, labels) in enumerate(train_loader): # 배치 단위로 학습, 한 번의 배치에서 128개씩 모델이 학습\n",
        "# Training Loop\n",
        "   images = images.to(device)\n",
        "   labels = labels.to(device)\n",
        "   optimizer.zero_grad() # 이전 기울기 초기화\n",
        "   outputs = model(images) # 순전파 실행\n",
        "   loss = criterion(outputs, labels) # 손실 계산\n",
        "   loss.backward() # 역전파를 수행하여 가중치에 대한 기울기 계산\n",
        "   optimizer.step() # 가중치 업데이트\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "# Test Loop\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images) # 모델이 예측한 결과\n",
        "    _, predicted = torch.max(outputs.data, 1) # 예측값 중 가장 높은 확률을 가진 클래스 선택\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum() # 맞춘 개수를 합산\n",
        "  end_time = time.time()\n",
        "  accuracy = 100 * correct.item() / total # 정확도 계산\n",
        "  elapsed_time = end_time - start_time\n",
        "  print('Epochs: {}. Loss: {}. Accuracy: {}, Elapsed time: {} sec'.format(epoch, loss.item(), accuracy, elapsed_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "BBIihNbRBbCU",
        "outputId": "160749cb-3385-45dc-9ab6-e789c6c73318"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/m4.jpeg'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6c58b7d86e11>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/m4.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m t = transforms.Compose([\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# VGG 입력 크기 맞추기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/m4.jpeg'"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "img = Image.open('/content/m4.jpeg')\n",
        "\n",
        "t = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # VGG 입력 크기 맞추기\n",
        "    transforms.ToTensor(),          # Tensor 변환\n",
        "    transforms.Normalize(mean=[0.4194, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])  # 정규화\n",
        "    # 입력 데이터를 정규화하는 과정\n",
        "    # 정규화 - 각 픽셀 값을 일정한 범위로 조정하는 과정. 보통 딥러닝 모델에서는 픽셀 값을 평균 0, 표준편차 1에 가깝게 정규화하면 학습이 더 잘된다\n",
        "    # 위 값들은 훈련 데이터셋(CIFAR-10)에서 R, G, B 채널별 평균과 표준편차를 미리 계산한 값이다 (전체 데이터셋에서 R, G, B 채널별 평균과 표준편차를 계산한 값)\n",
        "])\n",
        "\n",
        "img_tensor = t(img) # 변환 적용\n",
        "img_tensor = img_tensor.unsqueeze(0) # 배치 차원 추가 (1, 3, 224, 224)\n",
        "\n",
        "img_tensor = img_tensor.to(device)\n",
        "outputs = model(img_tensor)\n",
        "\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "print(class_names[predicted])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb-Zo5yOj9ac"
      },
      "source": [
        "## 2. ResNet with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdUXnBp7J57-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQeESvzij9ad"
      },
      "source": [
        "### Implementing ResNet\n",
        "\n",
        "> 1. **Dataset**\n",
        ">> - The same dataset used for VGGNet\n",
        ">\n",
        "> 2. **Network architecture**\n",
        ">> - 50-layer ResNet with **bottleneck blocks**. <br>\n",
        "     Note. The initial convolution layer (i.e., conv1) is different from the one in the paper &<br>\n",
        "     the initial max-pooling layer is removed (because the size of CIFAR-10 images is too small).\n",
        ">> - ReLU activation.\n",
        ">> - Strided convolution for down-sampling instead of max-pooling layer. <br>\n",
        "     Note. Once down-sampled, a $1\\times1$ convolution/stride 2 is applied to residual for expanding the channel of the residual.\n",
        ">> - No dropout for simplicity.\n",
        ">> - Batch-normalization after every convolution.\n",
        ">>\n",
        ">>\n",
        ">> <table><tr>\n",
        ">> <td> <img src=\"https://docs.google.com/uc?export=download&id=1ZYDfpVBFBvQnVezVcJqRxwh09rUVmxwD\" alt=\"no_image\" style=\"width: 500px;\"/> </td>\n",
        ">> <td> <img src=\"https://docs.google.com/uc?export=download&id=1JNEea1G-5yOKVLmSCkiYAEJ0HXOys0CR\" alt=\"no_image\" style=\"width: 300px;\"/> </td>\n",
        ">> </tr></table>\n",
        ">>\n",
        ">> <img src=\"https://docs.google.com/uc?export=download&id=1vY0ys5KAZmMlOKk8Dcv7eAV8pZ9cawzJ\" alt=\"no_image\" style=\"width: 870px;\"/>\n",
        ">>\n",
        ">> <font size=\"0.5\"> Figures from <br>\n",
        ">> [1] https://www.codeproject.com/Articles/1248963/Deep-Learning-using-Python-plus-Keras-Chapter-Re  <br>\n",
        ">> [2] Rezende et al., *Signal Processing: Image Communication*, 2018. </font>\n",
        ">\n",
        "> 3. **Loss function**\n",
        ">> - Cross-entropy loss between outputs & ground-truths. <br>\n",
        ">\n",
        "> 4. **Training**\n",
        ">> - Default weight initialization for simplicity.\n",
        ">> - SGD optimizer with `learning rate = 1e-2`, `momentum = 0.9`, and `weight_decay = 5e-4`.\n",
        ">> - 15 epochs without learning rate scheduling.\n",
        ">\n",
        "> 5. **Evaluation metric**\n",
        ">> - Classification accuracy (i.e., the percentage of correct predictions).\n",
        ">\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFlYgF2ZKFfe"
      },
      "source": [
        "### Implement ResNet50 and train it with the CIFAR 10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K17w3Z0KB8H",
        "outputId": "33b2285a-e544-4094-b580-5dfed0f6dbae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 3: CREATE MODEL CLASS (ResNet-50)\n",
            "STEP 4: INSTANTIATE MODEL CLASS\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (init_block): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (ResBlock1): Sequential(\n",
              "    (0): ResNet_block(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResNet_block(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (2): ResNet_block(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (ResBlock2): Sequential(\n",
              "    (0): ResNet_block(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2))\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResNet_block(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (2): ResNet_block(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (3): ResNet_block(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (ResBlock3): Sequential(\n",
              "    (0): ResNet_block(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResNet_block(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (2): ResNet_block(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (3): ResNet_block(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (4): ResNet_block(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (5): ResNet_block(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (ResBlock4): Sequential(\n",
              "    (0): ResNet_block(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResNet_block(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (2): ResNet_block(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (classifier): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"STEP 3: CREATE MODEL CLASS (ResNet-50)\")\n",
        "cfg = [3, 4, 6, 3]\n",
        "\n",
        "class ResNet_block(nn.Module):\n",
        "  def __init__(self, in_c, intra_c, out_c, down_sample=False):\n",
        "    super(ResNet_block, self).__init__()\n",
        "\n",
        "    if down_sample:\n",
        "      stride=2\n",
        "    else:\n",
        "      stride=1\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=in_c, out_channels=intra_c, kernel_size=1, stride=stride, padding=0)\n",
        "    self.bn1 = nn.BatchNorm2d(intra_c)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=intra_c, out_channels=intra_c, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(intra_c)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=intra_c, out_channels=out_c, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn3 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if in_c != out_c or stride != 1:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=in_c, out_channels=out_c, kernel_size=1, stride=stride, padding=0),\n",
        "          nn.BatchNorm2d(out_c)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity=x\n",
        "    out=self.conv1(x)\n",
        "    out=self.bn1(out)\n",
        "    out=F.relu(out)\n",
        "\n",
        "    out=self.conv2(out)\n",
        "    out=self.bn2(out)\n",
        "    out=F.relu(out)\n",
        "\n",
        "    out=self.conv3(out)\n",
        "    out=self.bn3(out)\n",
        "\n",
        "    identity=self.shortcut(identity)\n",
        "    out= F.relu(out+identity)\n",
        "    return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.init_block = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, 3, 1, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "    self.ResBlock1 = self._make_layers(in_c=64, intra_c=64, out_c=256, num_block=cfg[0], down_sample=False)\n",
        "    self.ResBlock2 = self._make_layers(in_c=256, intra_c=128, out_c=512, num_block=cfg[1], down_sample=True)\n",
        "    self.ResBlock3 = self._make_layers(in_c=512, intra_c=256, out_c=1024, num_block=cfg[2], down_sample=True)\n",
        "    self.ResBlock4 = self._make_layers(in_c=1024, intra_c=512, out_c=2048, num_block=cfg[3], down_sample=True)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.classifier = nn.Linear(2048, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.init_block(x)\n",
        "    out = self.ResBlock1(out)\n",
        "    out = self.ResBlock2(out)\n",
        "    out = self.ResBlock3(out)\n",
        "    out = self.ResBlock4(out)\n",
        "    out = self.avgpool(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.classifier(out)\n",
        "    return out\n",
        "\n",
        "  def _make_layers(self, in_c, intra_c, out_c, num_block, down_sample):\n",
        "    layers = []\n",
        "    # first block\n",
        "    layers.append(ResNet_block(in_c=in_c, intra_c=intra_c, out_c=out_c, down_sample=down_sample))\n",
        "    # intermediate blocks\n",
        "    for _ in range(num_block-1):\n",
        "      layers.append(ResNet_block(in_c=out_c, intra_c=intra_c, out_c=out_c, down_sample=False))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "print('STEP 4: INSTANTIATE MODEL CLASS')\n",
        "model = ResNet()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB0aJVL3Musp",
        "outputId": "52452b5f-df0a-4abd-a9ca-bb256bf1aaa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 5: INSTANTIATE LOSS CLASS\n",
            "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
            "STEP 7: TRAIN THE MODEL\n",
            "Epochs: 0. Loss: 0.6492182612419128. Accuracy: 71.66666666666667, Elapsed time: 49.74346137046814 sec\n",
            "Epochs: 1. Loss: 0.8275130391120911. Accuracy: 76.56666666666666, Elapsed time: 48.13759636878967 sec\n",
            "Epochs: 2. Loss: 0.3531716763973236. Accuracy: 80.1, Elapsed time: 48.7548553943634 sec\n",
            "Epochs: 3. Loss: 0.521026611328125. Accuracy: 81.43333333333334, Elapsed time: 48.48884105682373 sec\n",
            "Epochs: 4. Loss: 0.27250200510025024. Accuracy: 82.13333333333334, Elapsed time: 48.66456484794617 sec\n",
            "Epochs: 5. Loss: 0.8171334862709045. Accuracy: 81.9, Elapsed time: 48.59889531135559 sec\n",
            "Epochs: 6. Loss: 0.4261429011821747. Accuracy: 82.6, Elapsed time: 48.718549966812134 sec\n",
            "Epochs: 7. Loss: 0.46613264083862305. Accuracy: 83.16666666666667, Elapsed time: 48.557640075683594 sec\n",
            "Epochs: 8. Loss: 0.37935948371887207. Accuracy: 81.1, Elapsed time: 48.783058881759644 sec\n",
            "Epochs: 9. Loss: 0.26849564909935. Accuracy: 85.03333333333333, Elapsed time: 48.63742256164551 sec\n",
            "Epochs: 10. Loss: 0.38162386417388916. Accuracy: 82.26666666666667, Elapsed time: 48.711381673812866 sec\n",
            "Epochs: 11. Loss: 0.2513750195503235. Accuracy: 81.8, Elapsed time: 48.69909191131592 sec\n",
            "Epochs: 12. Loss: 0.06939416378736496. Accuracy: 85.13333333333334, Elapsed time: 48.70232844352722 sec\n",
            "Epochs: 13. Loss: 0.07596468180418015. Accuracy: 82.1, Elapsed time: 48.74427270889282 sec\n",
            "Epochs: 14. Loss: 0.24344933032989502. Accuracy: 84.73333333333333, Elapsed time: 48.64358448982239 sec\n"
          ]
        }
      ],
      "source": [
        "print('STEP 5: INSTANTIATE LOSS CLASS')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print('STEP 6: INSTANTIATE OPTIMIZER CLASS')\n",
        "learning_rate = 1e-2\n",
        "momentum = 0.9\n",
        "weight_decay = 5e-4\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "print('STEP 7: TRAIN THE MODEL')\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "  end_time = time.time()\n",
        "  accuracy = 100 * correct.item() / total\n",
        "  elapsed_time = end_time - start_time\n",
        "  print('Epochs: {}. Loss: {}. Accuracy: {}, Elapsed time: {} sec'.format(epoch, loss.item(), accuracy, elapsed_time))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
